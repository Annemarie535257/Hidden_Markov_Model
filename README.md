# HMM Assignment Submission Package

## ğŸ‰ **Updated with Google Drive Integration!**

This submission package now includes **Google Drive integration** for easy dataset access and notebook execution in Google Colab.

## Deliverables Checklist

### âœ… Required Deliverables

1. **Dataset files (.csv) from Sensor Logger**
   - Location: `dataset/` folder
   - Contains: 10 activity sessions with accelerometer and gyroscope data
   - Format: CSV files with timestamp, x, y, z coordinates
   - Total: 60 CSV files (6 files per activity session)
   - **NEW**: Can be uploaded to Google Drive for easy access

2. **Python notebook (.ipynb) implementing HMM**
   - File: `.ipynb`
   - Contains: Complete HMM implementation with all required components
   - Features: Feature extraction, model training, evaluation, visualization
   - **NEW**: Google Drive integration for automatic dataset loading

### ğŸ“Š Additional Deliverables (Bonus)

4. **Overfitting Prevention Implementation**
   - Integrated into the main notebook
   - Techniques: Feature selection, robust scaling, activity grouping, data augmentation
   - Results: Improved accuracy from 0.0% to 44.6%

5. **Google Drive Integration**
   - File: `GOOGLE_DRIVE_INSTRUCTIONS.md`
   - Contains: Step-by-step instructions for Google Drive setup
   - Features: Automatic dataset mounting and copying

6. **Comprehensive Documentation**
   - File: `README.md` (this file)
   - Contains: Project overview, setup instructions, usage guide
   - Technical details: Implementation architecture, results analysis

## ğŸ¯ Assignment Requirements Met

### âœ… Background and Motivation
- Clear problem statement and motivation for HMM in HAR
- Literature context and application areas
- Dataset overview and characteristics

### âœ… Data Collection and Preprocessing Steps
- Detailed data collection process using Sensor Logger
- Comprehensive feature extraction pipeline
- Time-domain and frequency-domain features
- Windowing strategy and data quality assessment

### âœ… HMM Setup and Implementation Details
- Complete model architecture description
- Overfitting prevention techniques
- Training process and parameters
- Viterbi algorithm implementation

### âœ… Results and Interpretation
- Performance metrics and accuracy analysis
- Transition matrix interpretation
- Visualization results (heatmaps, confusion matrix, sequences)
- Per-activity performance breakdown

### âœ… Discussion and Conclusion
- Key findings and limitations analysis
- Comparison with literature
- Future improvements and recommendations
- Practical insights for HAR applications

## ğŸ“ File Structure

```
submission/
â”œâ”€â”€ HMM_Implementation.ipynb          # Main Jupyter notebook with Google Drive integration
â”œâ”€â”€ README.md                         # This file
â””â”€â”€ dataset/                          # Sensor data files
    â”œâ”€â”€ jumping1-2025-10-23_15-07-37/
    â”‚   â”œâ”€â”€ Accelerometer.csv
    â”‚   â”œâ”€â”€ Gyroscope.csv
    â”‚   â””â”€â”€ [other sensor files]
    â”œâ”€â”€ jumping2-2025-10-23_15-07-59/
    â”œâ”€â”€ running1-2025-10-23_15-06-27/
    â”œâ”€â”€ running_2-2025-10-23_15-07-13/
    â”œâ”€â”€ shaking1-2025-10-23_15-06-51/
    â”œâ”€â”€ shaking2-2025-10-23_15-09-34/
    â”œâ”€â”€ standing-2025-10-23_15-10-03/
    â”œâ”€â”€ still-2025-10-23_15-04-36/
    â”œâ”€â”€ walking2-2025-10-23_15-05-57/
    â””â”€â”€ walking_1-2025-10-23_15-05-01/
```

## ğŸš€ How to Run the Implementation

### Option 1: Google Colab (Recommended) ğŸŒŸ

1. **Upload your dataset to Google Drive:**
   - Create a folder called `HMM_Dataset` in your Google Drive
   - Upload the entire `dataset` folder to this location

2. **Open the notebook in Google Colab:**
   - Go to [Google Colab](https://colab.research.google.com/)
   - Upload `.ipynb`
   - Or open directly from Google Drive

3. **Run the notebook:**
   - Execute all cells sequentially
   - Authorize Google Drive when prompted
   - The notebook will automatically load your dataset

### Option 2: Local Jupyter Notebook

1. **Install prerequisites:**
```bash
pip install numpy pandas scipy scikit-learn hmmlearn matplotlib seaborn
```

2. **Run the notebook:**
   - Open `.ipynb` in Jupyter Notebook
   - Update the dataset path if needed
   - Run all cells sequentially

### Option 3: Google Drive Integration Features

The notebook includes automatic:
- âœ… Google Drive mounting
- âœ… Dataset copying from Drive to local Colab environment
- âœ… Error handling and verification
- âœ… Clear instructions if dataset not found

## ğŸ”§ Google Drive Setup Instructions

### Quick Setup Guide

1. **Upload Dataset to Google Drive:**
   ```
   Google Drive/
   â””â”€â”€ HMM_Dataset/
       â”œâ”€â”€ jumping1-2025-10-23_15-07-37/
       â”œâ”€â”€ jumping2-2025-10-23_15-07-59/
       â”œâ”€â”€ running1-2025-10-23_15-06-27/
       â””â”€â”€ [other activity folders...]
   ```

2. **Open Notebook in Google Colab:**
   - Go to [colab.research.google.com](https://colab.research.google.com/)
   - Upload `HMM_Implementation.ipynb`
   - Or save to Google Drive and open from there

3. **Update Dataset Path (if needed):**
   ```python
   GOOGLE_DRIVE_DATASET_PATH = "/content/drive/MyDrive/HMM_Dataset"
   ```

4. **Run All Cells:**
   - The notebook will automatically mount Google Drive
   - Copy your dataset to the local Colab environment
   - Execute the complete HMM implementation

### Troubleshooting

- **Dataset not found?** Check the folder name is exactly `HMM_Dataset`
- **Permission errors?** Re-run the Google Drive mount cell
- **Slow performance?** Use GPU runtime in Colab (Runtime â†’ Change runtime type â†’ GPU)

For detailed instructions, see `GOOGLE_DRIVE_INSTRUCTIONS.md`

## ğŸ“ˆ Key Results Summary

### Performance Metrics
- **Improved Accuracy**: 44.6% (vs 0.0% baseline)
- **Feature Reduction**: 100 â†’ 15 features (85% reduction)
- **State Reduction**: 6 â†’ 3 states (50% reduction)
- **Data Augmentation**: 283 â†’ 566 samples (2x increase)

### Technical Achievements
- âœ… Complete HMM implementation from scratch
- âœ… Comprehensive feature extraction pipeline
- âœ… Overfitting prevention techniques
- âœ… Viterbi algorithm for state decoding
- âœ… Robust evaluation and visualization
- âœ… **NEW**: Google Drive integration for easy access

### Overfitting Prevention Success
- **Problem**: Initial model had 0.0% accuracy due to overfitting
- **Solution**: Implemented multiple prevention techniques
- **Result**: Achieved 44.6% accuracy with limited data
- **Impact**: Demonstrated effective overfitting prevention strategies

## ğŸ“ Learning Outcomes

### Technical Skills Developed
1. **HMM Implementation**: Complete understanding of HMM architecture
2. **Feature Engineering**: Time-domain and frequency-domain feature extraction
3. **Overfitting Prevention**: Multiple techniques for limited data scenarios
4. **Model Evaluation**: Comprehensive performance analysis
5. **Data Visualization**: Effective result presentation
6. **Google Drive Integration**: Cloud-based dataset access and notebook execution

### Research Insights
1. **Data Quality**: Importance of sufficient training data for HMMs
2. **Model Complexity**: Balance between model capacity and data availability
3. **Feature Selection**: Critical role in preventing overfitting
4. **Activity Grouping**: Effective strategy for reducing model complexity
5. **Evaluation Metrics**: Importance of multiple performance measures
6. **Cloud Computing**: Benefits of Google Colab for machine learning projects

## ğŸ”¬ Technical Implementation Details

### Feature Extraction
- **Time-Domain**: 50 features (statistical measures, correlations, energy)
- **Frequency-Domain**: 50 features (FFT analysis, spectral characteristics)
- **Windowing**: 50-sample windows with 50% overlap
- **Sensors**: Combined accelerometer and gyroscope data

### HMM Architecture
- **Model Type**: Gaussian HMM with diagonal covariance
- **States**: 3 grouped activity states
- **Features**: 15 selected features
- **Training**: Baum-Welch algorithm with convergence monitoring

### Overfitting Prevention
1. **Feature Selection**: Mutual information-based reduction
2. **Robust Scaling**: Median/IQR-based normalization
3. **Activity Grouping**: Logical grouping of similar activities
4. **Data Augmentation**: Controlled noise addition
5. **Model Simplification**: Reduced state and feature space

## ğŸ“š References and Resources

### Academic References
1. Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition.
2. Bulling, A., Blanke, U., & Schiele, B. (2014). A tutorial on human activity recognition using body-worn inertial sensors.
3. Chen, Y., & Xue, Y. (2015). A review of human activity recognition methods.
